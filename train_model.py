import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
import os

# Chargement des donn√©es
print("Chargement des donn√©es...")
df = pd.read_csv('dataset_assurance_auto.csv')

# Pr√©paration des features
print("Pr√©paration des features...")

# Encodage des variables cat√©gorielles
le_marque = LabelEncoder()
le_type_vehicule = LabelEncoder()

df['Marque_encoded'] = le_marque.fit_transform(df['Marque'])
df['Type_Vehicule_encoded'] = le_type_vehicule.fit_transform(df['Type_Vehicule'])

# Conversion des bool√©ens en entiers
df['Place_Parking_int'] = df['Place_Parking'].astype(int)
df['Voiture_Entreprise_int'] = df['Voiture_Entreprise'].astype(int)

# S√©lection des features pour l'entra√Ænement
features = [
    'Marque_encoded', 'Type_Vehicule_encoded', 'Age_Vehicule', 
    'Valeur_Vehicule_DT', 'Kilometrage', 'Chevaux_Fiscaux',
    'Place_Parking_int', 'Voiture_Entreprise_int',
    'Age_Conducteur', 'Annees_Experience', 'Nombre_Accidents'
]

X = df[features]
y = df['Assurance_Recommandee']

# Division train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"Taille du jeu d'entra√Ænement: {X_train.shape[0]}")
print(f"Taille du jeu de test: {X_test.shape[0]}")

# Entra√Ænement du mod√®le Random Forest
print("\nEntra√Ænement du mod√®le Random Forest...")
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    class_weight='balanced'
)

rf_model.fit(X_train, y_train)

# Pr√©dictions
y_pred = rf_model.predict(X_test)

# √âvaluation du mod√®le
print("\n" + "="*50)
print("√âVALUATION DU MOD√àLE")
print("="*50)

accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")

print("\nRapport de classification d√©taill√©:")
print(classification_report(y_test, y_pred))

print("\nMatrice de confusion:")
cm = confusion_matrix(y_test, y_pred)
print(cm)

# Visualisation de la matrice de confusion
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Tiers', 'Tiers Plus', 'Tout Risque'],
            yticklabels=['Tiers', 'Tiers Plus', 'Tout Risque'])
plt.title('Matrice de Confusion')
plt.ylabel('Valeurs R√©elles')
plt.xlabel('Pr√©dictions')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.close()  # üî• √âvite d'afficher la fen√™tre

# Importance des features
print("\n" + "="*50)
print("IMPORTANCE DES FEATURES")
print("="*50)

feature_importance = pd.DataFrame({
    'feature': features,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print(feature_importance)

# Visualisation de l'importance des features
plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance, x='importance', y='feature')
plt.title('Importance des Features dans le Mod√®le Random Forest')
plt.xlabel('Importance')
plt.tight_layout()
plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
plt.close()  # üî• √âvite d'afficher la fen√™tre

# Test de quelques exemples
print("\n" + "="*50)
print("TESTS D'EXEMPLES")
print("="*50)

examples = X_test.head(10)
examples_pred = rf_model.predict(examples)
examples_actual = y_test.head(10).values

print("\nComparaison pr√©dictions vs r√©alit√© (10 premiers exemples):")
for i in range(len(examples)):
    print(f"Exemple {i+1}: Pr√©dit={examples_pred[i]}, R√©el={examples_actual[i]}, "
          f"Correct={'‚úì' if examples_pred[i] == examples_actual[i] else '‚úó'}")

# Analyse par type d'assurance
print("\n" + "="*50)
print("ANALYSE PAR TYPE D'ASSURANCE")
print("="*50)

for assurance_type in ['Tiers', 'Tiers Plus', 'Tout Risque']:
    mask = y_test == assurance_type
    if mask.sum() > 0:
        pred_for_type = y_pred[mask]
        correct = (pred_for_type == assurance_type).sum()
        total = len(pred_for_type)
        accuracy_type = correct / total
        print(f"{assurance_type}: {correct}/{total} ({accuracy_type*100:.1f}% correct)")

# Sauvegarde du mod√®le et des encodeurs
print("\n" + "="*50)
print("SAUVEGARDE DU MOD√àLE")
print("="*50)

joblib.dump(rf_model, 'insurance_model.pkl')
joblib.dump(le_marque, 'marque_encoder.pkl')
joblib.dump(le_type_vehicule, 'type_vehicule_encoder.pkl')

# V√©rification que les fichiers sont bien cr√©√©s
for filename in ['insurance_model.pkl', 'marque_encoder.pkl', 'type_vehicule_encoder.pkl']:
    if os.path.exists(filename):
        print(f"‚úÖ Fichier sauvegard√© : {filename}")
    else:
        print(f"‚ùå √âchec de la sauvegarde : {filename}")

# Sauvegarde des informations pour l'application
model_info = {
    'features': features,
    'marques': list(le_marque.classes_),
    'types_vehicules': list(le_type_vehicule.classes_),
    'accuracy': accuracy
}

joblib.dump(model_info, 'model_info.pkl')
if os.path.exists('model_info.pkl'):
    print("‚úÖ Informations du mod√®le sauvegard√©es: model_info.pkl")
else:
    print("‚ùå √âchec de la sauvegarde: model_info.pkl")

print("\n" + "="*50)
print("ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS!")
print("="*50)
print(f"Accuracy finale: {accuracy*100:.2f}%")
print("Fichiers g√©n√©r√©s :")
print("- insurance_model.pkl")
print("- marque_encoder.pkl")
print("- type_vehicule_encoder.pkl")
print("- model_info.pkl")
print("- confusion_matrix.png")
print("- feature_importance.png")
